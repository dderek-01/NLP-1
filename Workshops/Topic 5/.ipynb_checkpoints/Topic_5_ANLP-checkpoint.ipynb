{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 5: Dependency Parsing (ANLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries \n",
    "Run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(r'\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources')\n",
    "sys.path.append('/Users/juliewe/resources')\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import defaultdict,Counter\n",
    "from itertools import zip_longest\n",
    "from IPython.display import display\n",
    "from random import seed\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pylab as pylab\n",
    "%matplotlib inline\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'large',\n",
    "         'axes.titlesize':'large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'large'}\n",
    "pylab.rcParams.update(params)\n",
    "from pylab import rcParams\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy\n",
    "In the next topic, Topic 6, we will be investigating how to make a fine-grained analysis of the content of Amazon reviews. In particular, we will be analysing what the reviewer says about specific aspects of the product, e.g. what is said about the *plot* of a *film*. In preparation for that, in this notebook, we will be learning about dependency trees.\n",
    "\n",
    "Dependency trees allow us to see how the words in a sentence relate to one another grammatically. This contrasts with  what we've been doing up until now when determining the sentiment of a review; we've been viewing a document as an unordered bag of words.\n",
    "\n",
    "Up to this point we have been using varous NLP tools that form part of the NLTK. We now turn to an alternative, significantly more powerful NLP toolkit, one that provides state-of-the-art accuracy and state-of-the-art efficiency. \n",
    "\n",
    "We will be using something called [spaCy](https://spacy.io/). \n",
    "\n",
    "In this notebook we will be familiarising ourselves with many of the things that spaCy can do. One of the tools that spaCy contains is a non-monotonic arc-eager transition parser.  Being non-montonic means that it can potentially correct parsing mistakes made by the greedy approach in parsing garden-path sentences such as \"The horse raced past the barn fell.\"  See http://aclweb.org/anthology/D15-1162 for more information.\n",
    "\n",
    "Note that several of the examples that appear in this notebook have either been taken directly, or have been adapted from various spaCy tutorials found [here](https://spacy.io/docs/usage/tutorials).\n",
    "\n",
    "To load spaCy, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# we'll be using the English version of spaCy. German, French, Spanish versions are also available.\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review dataset\n",
    "We need some data to work with. Let's set up a dataset of dvd reviews, `dvd_reviews`. \n",
    "\n",
    "To do this, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sussex NLTK root directory is /Users/juliewe/resources\n",
      "The dvd review dataset contains 5491 reviews\n"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "\n",
    "# create a list containing the raw text of all of the available dvd reviews.\n",
    "dvd_reviews = [review for review in AmazonReviewCorpusReader().category(\"dvd\").raw()]\n",
    "print(\"The dvd review dataset contains {} reviews\".format(len(dvd_reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing a review with spaCy\n",
    "We now look at what spaCy produces when it analyses text. \n",
    "\n",
    "The following cell illustrates some (though by no means all) of the elements of the analysis. After being analysed by spaCy, much of the analysis is accessible through the tokens. Each token is an object that has a number of properties. See [here](https://spacy.io/docs/api/token) for a full list of a token's properties.\n",
    "\n",
    "Note: in general, when a property name ends with an underscore character, e.g.  `orth_`, that property returns a string (unicode) representation of the value for that property. This is useful when displaying output in a human-readable way. With no underscore, e.g. `orth`, the property returns the index of the value within the spaCy vocabulary.\n",
    "\n",
    "In the following cell, we see the following token properties being used:\n",
    "- `orth_`: the token's orthography.\n",
    "- `lemma_`: the uninflected form of the token.\n",
    "- `shape_`: the token shape.\n",
    "- `pos_`: the part of speech of the token.\n",
    "- `is_stop`: is the token a stop word or not?\n",
    "- `is_punc`: is the token punctuation or not?\n",
    "- `is_space`: is the token whitespace? Note that spacy tokeniser treates any sequence of whitespace characters beyond a single space as a token.\n",
    "- `like_num`: is the token a number?\n",
    "- `is_oov`: is the token an out-of-vocabulary word?\n",
    "- `prop`: the log probabilities of tokens, where the probabilities are estimated from a three billion word corpus, with simple Good-Turning smoothing;\n",
    "\n",
    "### Exercise\n",
    "Run the following cell several times so that you can look at the output for a variety of sentences.\n",
    "- Notice that parts of speech tags are upper case strings, e.g. `VERB`.\n",
    "- Look at places where the lemma is different from the token.\n",
    "- See if you can find sentences with out-of-vocabulary (oov) tokens.\n",
    "- What does the `shape` property capture?\n",
    "- See if you can figure out what this line is doing:\n",
    "```\n",
    "df.loc[:, 'stop?':'out of vocab.?'] = (df4.loc[:, 'stop?':'out of vocab.?']\n",
    "                                       .applymap(lambda x: 'Yes' if x else ''))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the sentence:\n",
      "TCM III was a good movie.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>number?</th>\n",
       "      <th>stop?</th>\n",
       "      <th>oov?</th>\n",
       "      <th>punctuation?</th>\n",
       "      <th>whitespace?</th>\n",
       "      <th>shape</th>\n",
       "      <th>log probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCM</td>\n",
       "      <td>tcm</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>XXX</td>\n",
       "      <td>-19.579313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>III</td>\n",
       "      <td>iii</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>XXX</td>\n",
       "      <td>-11.813502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>xxx</td>\n",
       "      <td>-5.404201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>x</td>\n",
       "      <td>-3.983075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>-6.718321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>movie</td>\n",
       "      <td>movie</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>-8.932445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>.</td>\n",
       "      <td>-3.072948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma    pos number? stop? oov? punctuation? whitespace? shape  \\\n",
       "0    TCM    tcm  PROPN      no    no   no           no          no   XXX   \n",
       "1    III    iii  PROPN      no    no   no           no          no   XXX   \n",
       "2    was     be   VERB      no   yes   no           no          no   xxx   \n",
       "3      a      a    DET      no   yes   no           no          no     x   \n",
       "4   good   good    ADJ      no    no   no           no          no  xxxx   \n",
       "5  movie  movie   NOUN      no    no   no           no          no  xxxx   \n",
       "6      .      .  PUNCT      no    no   no          yes          no     .   \n",
       "\n",
       "   log probability  \n",
       "0       -19.579313  \n",
       "1       -11.813502  \n",
       "2        -5.404201  \n",
       "3        -3.983075  \n",
       "4        -6.718321  \n",
       "5        -8.932445  \n",
       "6        -3.072948  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly choose a review\n",
    "review = random.choice(dvd_reviews)\n",
    "#run spaCy on the review\n",
    "parsed_review = nlp(review) # in spaCy we call parsed_review a Doc\n",
    "\n",
    "# get just the first sentence of the review\n",
    "parsed_sentence = next(parsed_review.sents) # in spaCy we call parsed_sentence a Span (of a Doc)\n",
    "\n",
    "token_attributes = [(token.orth_,\n",
    "                     token.lemma_,\n",
    "                     token.pos_,\n",
    "                     token.like_num,\n",
    "                     token.is_stop,\n",
    "                     token.is_oov,\n",
    "                     token.is_punct,\n",
    "                     token.is_space,\n",
    "                     token.shape_,\n",
    "                     token.prob,\n",
    "                    )\n",
    "                    for token in parsed_sentence]\n",
    "\n",
    "df = pd.DataFrame(token_attributes,\n",
    "                   columns=['text',\n",
    "                            'lemma',\n",
    "                            \"pos\",\n",
    "                            'number?',\n",
    "                            'stop?',\n",
    "                            'oov?',\n",
    "                            'punctuation?',\n",
    "                            'whitespace?',\n",
    "                            'shape',\n",
    "                            'log probability',\n",
    "                           ])\n",
    "\n",
    "df.loc[:, 'number?':'whitespace?'] = (df.loc[:, 'number?':'whitespace?']\n",
    "                                       .applymap(lambda x: 'yes' if x else 'no'))\n",
    "\n",
    "print('Analysis of the sentence:\\n{}'.format(parsed_sentence.text))                                               \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of spaCy objects\n",
    "\n",
    "Three classes of objects make up a spaCy analysis:\n",
    "- A document.\n",
    "- A span. \n",
    " - this as a subsequence, or slice, of the parsed document and could be a sentence or phrase.\n",
    "- A token.\n",
    "\n",
    "Each of these has various properties.\n",
    "\n",
    "In each of the following three code cells you will see code that uses `dir` to display the full set of such properties for each kind of object. \n",
    "\n",
    "We begin with a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t count_by\n",
      "\t doc\n",
      "\t ents\n",
      "\t from_array\n",
      "\t from_bytes\n",
      "\t has_vector\n",
      "\t is_parsed\n",
      "\t is_tagged\n",
      "\t mem\n",
      "\t merge\n",
      "\t noun_chunks\n",
      "\t noun_chunks_iterator\n",
      "\t read_bytes\n",
      "\t sentiment\n",
      "\t sents\n",
      "\t similarity\n",
      "\t string\n",
      "\t tensor\n",
      "\t text\n",
      "\t text_with_ws\n",
      "\t to_array\n",
      "\t to_bytes\n",
      "\t user_data\n",
      "\t user_hooks\n",
      "\t user_span_hooks\n",
      "\t user_token_hooks\n",
      "\t vector\n",
      "\t vector_norm\n",
      "\t vocab\n"
     ]
    }
   ],
   "source": [
    "review = random.choice(dvd_reviews)\n",
    "parsed_review = nlp(review) # in spaCy we call parsed_review a Doc\n",
    "      \n",
    "for prop in dir(parsed_review):\n",
    "    if not prop.startswith('_'):\n",
    "        print(\"\\t\",prop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at the properties of spans. In this case, our span is a sentence from the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t doc\n",
      "\t end\n",
      "\t end_char\n",
      "\t ent_id\n",
      "\t ent_id_\n",
      "\t has_vector\n",
      "\t label\n",
      "\t label_\n",
      "\t lefts\n",
      "\t lemma_\n",
      "\t lower_\n",
      "\t merge\n",
      "\t noun_chunks\n",
      "\t orth_\n",
      "\t rights\n",
      "\t root\n",
      "\t sent\n",
      "\t sentiment\n",
      "\t similarity\n",
      "\t start\n",
      "\t start_char\n",
      "\t string\n",
      "\t subtree\n",
      "\t text\n",
      "\t text_with_ws\n",
      "\t upper_\n",
      "\t vector\n",
      "\t vector_norm\n"
     ]
    }
   ],
   "source": [
    "review = random.choice(dvd_reviews)\n",
    "parsed_review = nlp(review) # in spaCy we call parsed_review a Doc\n",
    "parsed_sentence = next(parsed_review.sents) # in spaCy we call parsed_sentence a Span (of a Doc)\n",
    "\n",
    "for prop in dir(parsed_sentence):\n",
    "    if not prop.startswith('_'):\n",
    "        print(\"\\t\",prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, we look at the properties of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ancestors\n",
      "\t check_flag\n",
      "\t children\n",
      "\t cluster\n",
      "\t conjuncts\n",
      "\t dep\n",
      "\t dep_\n",
      "\t doc\n",
      "\t ent_id\n",
      "\t ent_id_\n",
      "\t ent_iob\n",
      "\t ent_iob_\n",
      "\t ent_type\n",
      "\t ent_type_\n",
      "\t has_repvec\n",
      "\t has_vector\n",
      "\t head\n",
      "\t i\n",
      "\t idx\n",
      "\t is_alpha\n",
      "\t is_ancestor\n",
      "\t is_ancestor_of\n",
      "\t is_ascii\n",
      "\t is_bracket\n",
      "\t is_digit\n",
      "\t is_left_punct\n",
      "\t is_lower\n",
      "\t is_oov\n",
      "\t is_punct\n",
      "\t is_quote\n",
      "\t is_right_punct\n",
      "\t is_space\n",
      "\t is_stop\n",
      "\t is_title\n",
      "\t lang\n",
      "\t lang_\n",
      "\t left_edge\n",
      "\t lefts\n",
      "\t lemma\n",
      "\t lemma_\n",
      "\t lex_id\n",
      "\t like_email\n",
      "\t like_num\n",
      "\t like_url\n",
      "\t lower\n",
      "\t lower_\n",
      "\t n_lefts\n",
      "\t n_rights\n",
      "\t nbor\n",
      "\t norm\n",
      "\t norm_\n",
      "\t orth\n",
      "\t orth_\n",
      "\t pos\n",
      "\t pos_\n",
      "\t prefix\n",
      "\t prefix_\n",
      "\t prob\n",
      "\t rank\n",
      "\t repvec\n",
      "\t right_edge\n",
      "\t rights\n",
      "\t sentiment\n",
      "\t shape\n",
      "\t shape_\n",
      "\t similarity\n",
      "\t string\n",
      "\t subtree\n",
      "\t suffix\n",
      "\t suffix_\n",
      "\t tag\n",
      "\t tag_\n",
      "\t text\n",
      "\t text_with_ws\n",
      "\t vector\n",
      "\t vector_norm\n",
      "\t vocab\n",
      "\t whitespace_\n"
     ]
    }
   ],
   "source": [
    "review = random.choice(dvd_reviews)\n",
    "parsed_review = nlp(review) # in spaCy we call parsed_review a Doc\n",
    "parsed_sentence = next(parsed_review.sents) # in spaCy we call parsed_sentence a Span (of a Doc)\n",
    "\n",
    "for prop in dir(parsed_sentence[0]):\n",
    "    if not prop.startswith('_'):\n",
    "        print(\"\\t\",prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency trees in spaCy\n",
    "We are now ready to look at dependency trees.\n",
    "\n",
    "Dependency trees are graphs that are used to describe the syntax of a sentence. They do this by specifying relationship between the tokens in the sentence. The vertices of the graph are the tokens and the edges of the graph capture grammatical relationship between tokens, e.g. that a noun is the subject of a verb. They are called dependency **trees** because the graph is a tree.\n",
    "\n",
    "The following visualisation shows the a dependency tree produced by spaCy for the sentence  \n",
    "\"*However, the plot was predictable.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dependency tree example](./img/example_dependency_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerise\n",
    "In order to get a sense of what dependency trees produced by spaCy look like, take a look at a demo of spaCy's parser \n",
    "which can be found [here](https://demos.explosion.ai/displacy).\n",
    "\n",
    "In the box at the top (the one with the magnifying glass icon on its right), type in a sentence, run the parser, and examine the output. Try this for a few sentences.\n",
    "\n",
    "Here are some things to look out for:\n",
    "- Across the bottom of the tree, you will see each token with its part-of-speech shown below.\n",
    " - A full list of the parts of speech tag set can be found [here](https://spacy.io/docs/api/annotation#pos-tagging).\n",
    " - The tokens are shown in the order that they appear in the text.\n",
    " - Use `spacy.explain` to get a brief explanatin of a symbol, e.g. try `spacy.explain(\"JJ\")`.\n",
    "- Above the tokens you see **directed, labelled edges**. \n",
    " - Each edge specifies a dependency between two tokens in the sentence.\n",
    " - It is the edges that provide the syntactic analysis of the sentence.  \n",
    " - Each edge connects a **head** with one of its **dependents**. \n",
    " - The edges are directed **from** the head **to** the dependent.\n",
    " - The edges are labelled by the name of the dependency relation. \n",
    " - A full set of dependency relations can be found [here](https://spacy.io/docs/api/annotation#dependency-parsing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with dependency trees in spaCy\n",
    "Tokens are associated with two properties that encode the dependency tree that spaCy has assigned to a sentence.\n",
    "- `token.head`: this gives the token in the sentence that is the head of this token.\n",
    "- `token.dep_`: this gives the label of the dependency relation that links `token.head` to `token`.\n",
    "\n",
    "Note that when `token` is the root of the dependency tree `token.head == token`.\n",
    "\n",
    "### Exerise\n",
    "Run the cell below and inspect the output. \n",
    "- Notice that dependency labels are lower case strings, e.g. `nsubj`.\n",
    "- Notice the token that is at the root of the dependency tree has itself as its head.\n",
    "- Type the same sentence into the [spaCy parser demo](https://demos.explosion.ai/displacy) and check that each line of output is compatible with the tree being displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the sentence:\n",
      "I have to admit: this Adam Sandler no-brainer is hilarious, just had me laughing right from the start.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>aux</td>\n",
       "      <td>admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admit</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>Sandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sandler</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>ADV</td>\n",
       "      <td>det</td>\n",
       "      <td>brainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>brainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brainer</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td>relcl</td>\n",
       "      <td>Sandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hilarious</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>acomp</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>just</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>had</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>me</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>laughing</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>right</td>\n",
       "      <td>ADV</td>\n",
       "      <td>acomp</td>\n",
       "      <td>laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>start</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text    pos       dep      head\n",
       "0           I   PRON     nsubj      have\n",
       "1        have   VERB      ROOT      have\n",
       "2          to   PART       aux     admit\n",
       "3       admit   VERB     xcomp      have\n",
       "4           :  PUNCT     punct     admit\n",
       "5        this    DET       det       had\n",
       "6        Adam  PROPN  compound   Sandler\n",
       "7     Sandler  PROPN     nsubj       had\n",
       "8          no    ADV       det   brainer\n",
       "9           -  PUNCT     punct   brainer\n",
       "10    brainer   NOUN     nsubj        is\n",
       "11         is   VERB     relcl   Sandler\n",
       "12  hilarious    ADJ     acomp        is\n",
       "13          ,  PUNCT     punct        is\n",
       "14       just    ADV    advmod       had\n",
       "15        had   VERB     ccomp     admit\n",
       "16         me   PRON     nsubj  laughing\n",
       "17   laughing   VERB     ccomp       had\n",
       "18      right    ADV     acomp  laughing\n",
       "19       from    ADP      prep  laughing\n",
       "20        the    DET       det     start\n",
       "21      start   NOUN      pobj      from\n",
       "22          .  PUNCT     punct      have"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly choose a review\n",
    "review = random.choice(dvd_reviews)\n",
    "#run spaCy on the review\n",
    "parsed_review = nlp(review)\n",
    "# get just the first sentence of the review\n",
    "parsed_sentence = next(parsed_review.sents)\n",
    "\n",
    "token_attributes = [(token.orth_,\n",
    "                     token.pos_,\n",
    "                     token.dep_,\n",
    "                     token.head,\n",
    "                    )\n",
    "                    for token in parsed_sentence]\n",
    "\n",
    "df = pd.DataFrame(token_attributes,\n",
    "                   columns=['text',\n",
    "                            \"pos\",\n",
    "                            \"dep\",\n",
    "                            \"head\",\n",
    "                           ])\n",
    "                                               \n",
    "print('Analysis of the sentence:\\n{}'.format(parsed_sentence.text))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "In the cell below, you will find code that shows the verb tokens in a review together with an indication of whether they appeared (at least once in the review) in an `nsubj` relation with another token.\n",
    "\n",
    "Make a copy of this cell, and in the new cell, adapt the code so that so that the output also includes an additional column showing whether the verb tokens also appeared in a sentence in a situation where the token had both a `nsubj` relationship with some other token and a `dobj` relation with yet some other token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "This entire movie could have run in only 20 minutes and you wouldn't miss anything and might even enjoy it. Unfortunately it ran 88 minutes too long and I couldn't wait for it to end.  I saw it in the theater and the people all around me were all complaining how boring it was. At least a quarter of them walked out before the end. It's that bad. It's a shame, I love a good suspense/horror movie and the decent actors in this movies were waisted\n",
      "\n",
      "Review:\n",
      "This entire movie could have run in only 20 minutes and you wouldn't miss anything and might even enjoy it. Unfortunately it ran 88 minutes too long and I couldn't wait for it to end.  I saw it in the theater and the people all around me were all complaining how boring it was. At least a quarter of them walked out before the end. It's that bad. It's a shame, I love a good suspense/horror movie and the decent actors in this movies were waisted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>were</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miss</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walked</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>were</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>enjoy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>complaining</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waisted</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>would</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>run</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>could</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wait</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>love</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ran</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>end</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>might</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>saw</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>could</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           verb has nsubj?\n",
       "0          were           \n",
       "1          miss        yes\n",
       "2            's        yes\n",
       "3        walked        yes\n",
       "4          were        yes\n",
       "5         enjoy           \n",
       "6          have           \n",
       "7   complaining        yes\n",
       "8       waisted           \n",
       "9            's        yes\n",
       "10          was        yes\n",
       "11        would           \n",
       "12          run        yes\n",
       "13        could           \n",
       "14         wait        yes\n",
       "15         love        yes\n",
       "16          ran        yes\n",
       "17          end        yes\n",
       "18        might           \n",
       "19          saw        yes\n",
       "20        could           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "If you are looking for a good movie to buy for your child, pass on this one. This movie has so many drug references, i can't even begin to explain.(trust me, I just so happen to have taken acid before) This is a movie that NEVER should have been directed toward children. \n",
      "  \n",
      "   If you want your child to be drug free when he/she grows up, do not buy this\n",
      "\n",
      "Review:\n",
      "If you are looking for a good movie to buy for your child, pass on this one. This movie has so many drug references, i can't even begin to explain.(trust me, I just so happen to have taken acid before) This is a movie that NEVER should have been directed toward children. \n",
      "  \n",
      "   If you want your child to be drug free when he/she grows up, do not buy this\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>explain.(trust</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>happen</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>be</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taken</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>should</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>has</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grows</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ca</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pass</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>looking</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>directed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>want</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>begin</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              verb has nsubj?\n",
       "0              are           \n",
       "1             been           \n",
       "2   explain.(trust           \n",
       "3              buy        yes\n",
       "4              buy           \n",
       "5               is        yes\n",
       "6             have           \n",
       "7           happen        yes\n",
       "8               be        yes\n",
       "9            taken           \n",
       "10          should           \n",
       "11             has        yes\n",
       "12           grows        yes\n",
       "13              ca        yes\n",
       "14            pass        yes\n",
       "15              do           \n",
       "16         looking        yes\n",
       "17        directed           \n",
       "18            want        yes\n",
       "19           begin           \n",
       "20            have           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Fun to watch but my 9 1/2 yr. old daughter could not follow the moves.  Neither could I for that matter.  We tried to learn the moves through \"breaking it down\" but there is just not enough repetition.  Too complicated. \n",
      "\n",
      "Review:\n",
      "Fun to watch but my 9 1/2 yr. old daughter could not follow the moves.  Neither could I for that matter.  We tried to learn the moves through \"breaking it down\" but there is just not enough repetition.  Too complicated. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>could</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>could</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>follow</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tried</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breaking</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>watch</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>learn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       verb has nsubj?\n",
       "0     could           \n",
       "1     could        yes\n",
       "2    follow        yes\n",
       "3     tried        yes\n",
       "4  breaking           \n",
       "5     watch           \n",
       "6        is           \n",
       "7     learn           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Every review I've read about this movie pops and fizzes with praise and I just don't get it.  No one speaks until practically 10 minutes into it, and by then you're so confused by the random scenes thrown together and the cyrilic letters, it makes it hard to enjoy what comes next.  If you like extremely BROAD slapstick humor and find that totally charming, then I guess I can see the appeal.  Everyone talks about how this movie spawned so many catch phrases.  I have to wonder what they could be: \"Damned Melon!\" or \"I passed out when I broke my wrist, and when I woke up, the cast was already on!\"???  I will say listening to the dubbed english and having the english subtitles on at the same time does add some humor, because they say completely different things, or omit speech altogether.  In sum, don't waste your time\n",
      "\n",
      "Review:\n",
      "Every review I've read about this movie pops and fizzes with praise and I just don't get it.  No one speaks until practically 10 minutes into it, and by then you're so confused by the random scenes thrown together and the cyrilic letters, it makes it hard to enjoy what comes next.  If you like extremely BROAD slapstick humor and find that totally charming, then I guess I can see the appeal.  Everyone talks about how this movie spawned so many catch phrases.  I have to wonder what they could be: \"Damned Melon!\" or \"I passed out when I broke my wrist, and when I woke up, the cast was already on!\"???  I will say listening to the dubbed english and having the english subtitles on at the same time does add some humor, because they say completely different things, or omit speech altogether.  In sum, don't waste your time\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guess</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>listening</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wonder</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fizzes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thrown</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>waste</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>talks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speaks</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>broke</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spawned</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>say</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>read</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>see</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>passed</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>be</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>could</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>omit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>catch</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>will</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>enjoy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>can</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'re</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>say</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>get</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>find</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pops</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>makes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>woke</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Damned</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>add</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>like</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>have</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>'ve</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dubbed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>does</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>having</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb has nsubj?\n",
       "0         was        yes\n",
       "1       guess        yes\n",
       "2          do           \n",
       "3   listening           \n",
       "4      wonder           \n",
       "5      fizzes           \n",
       "6      thrown           \n",
       "7       waste           \n",
       "8       talks           \n",
       "9      speaks        yes\n",
       "10      broke        yes\n",
       "11      comes        yes\n",
       "12    spawned        yes\n",
       "13        say        yes\n",
       "14       read        yes\n",
       "15        see        yes\n",
       "16     passed        yes\n",
       "17         be        yes\n",
       "18      could           \n",
       "19       omit           \n",
       "20      catch        yes\n",
       "21       will           \n",
       "22      enjoy           \n",
       "23        can           \n",
       "24        're        yes\n",
       "25        say        yes\n",
       "26        get        yes\n",
       "27       find           \n",
       "28       pops        yes\n",
       "29      makes        yes\n",
       "30       woke        yes\n",
       "31     Damned           \n",
       "32        add           \n",
       "33       like        yes\n",
       "34       have        yes\n",
       "35        've           \n",
       "36     dubbed           \n",
       "37         do           \n",
       "38       does           \n",
       "39     having           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "The acting was very good. The pace was adequate. However, the plot was predictable. The movie just reeks of the intelligent thriller syndrome. Clive's character kept calling this the perfect robbery. The characters talk about the relative intelligence of the other characters or how the other characters can't possibly know what is going on. I'm still not sure what Jody Foster's character brings to the plot.  \n",
      "\n",
      "Any way, they do stupid things. The bank robbers dig a latrine in a storage closet. You don't know the hole is a latrine until the end of the movie. However, they do call it a \"s--thole during the movie. They spent hours on this hole. Why not use a bucket instead of a hole in the floor for a latrine? They even brought buckets in with them. They were disguised as painters. Why couldn't Clive's character use a bucket with chemical treatments instead of a hole in a floor of a bank for a latrine. \n",
      "\n",
      "Finding plot holes in this movie is like shooting fish in the barrel. Furthermore, the plot is so predictable that it made the movie drag. I have to be honest, I didn't guess the ending. I kicked myself for they gave plenty of clues. For example, a big one is the title of the movie. However, the lame clues (the s--thole) acted like red herrings. They threw me off the scent. \n",
      "\n",
      "Review:\n",
      "The acting was very good. The pace was adequate. However, the plot was predictable. The movie just reeks of the intelligent thriller syndrome. Clive's character kept calling this the perfect robbery. The characters talk about the relative intelligence of the other characters or how the other characters can't possibly know what is going on. I'm still not sure what Jody Foster's character brings to the plot.  \n",
      "\n",
      "Any way, they do stupid things. The bank robbers dig a latrine in a storage closet. You don't know the hole is a latrine until the end of the movie. However, they do call it a \"s--thole during the movie. They spent hours on this hole. Why not use a bucket instead of a hole in the floor for a latrine? They even brought buckets in with them. They were disguised as painters. Why couldn't Clive's character use a bucket with chemical treatments instead of a hole in a floor of a bank for a latrine. \n",
      "\n",
      "Finding plot holes in this movie is like shooting fish in the barrel. Furthermore, the plot is so predictable that it made the movie drag. I have to be honest, I didn't guess the ending. I kicked myself for they gave plenty of clues. For example, a big one is the title of the movie. However, the lame clues (the s--thole) acted like red herrings. They threw me off the scent. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>threw</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kicked</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>be</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acted</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disguised</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gave</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>did</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brought</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'m</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>call</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>know</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>could</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>going</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kept</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Finding</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>use</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>calling</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>know</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dig</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>guess</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>do</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>brings</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>shooting</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>talk</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>have</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>were</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ca</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>use</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb has nsubj?\n",
       "0       Clive           \n",
       "1       threw        yes\n",
       "2         was        yes\n",
       "3          do           \n",
       "4      kicked        yes\n",
       "5          be           \n",
       "6       acted        yes\n",
       "7   disguised           \n",
       "8        gave        yes\n",
       "9        made        yes\n",
       "10         is           \n",
       "11        did           \n",
       "12    brought        yes\n",
       "13         is           \n",
       "14         is        yes\n",
       "15         'm        yes\n",
       "16       call        yes\n",
       "17        was        yes\n",
       "18      spent        yes\n",
       "19       know        yes\n",
       "20         is        yes\n",
       "21      could           \n",
       "22      going        yes\n",
       "23       kept        yes\n",
       "24    Finding           \n",
       "25        use           \n",
       "26    calling           \n",
       "27       know        yes\n",
       "28        dig        yes\n",
       "29      guess        yes\n",
       "30         do        yes\n",
       "31         is        yes\n",
       "32     brings        yes\n",
       "33   shooting           \n",
       "34       talk        yes\n",
       "35       have        yes\n",
       "36       were           \n",
       "37         ca           \n",
       "38         do           \n",
       "39        use           \n",
       "40        was        yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Wedding Crashers is the kinda film alot of people will love because it is stupid but alot of others like myself, won't enjoy. two womanizers fall in love, one because he finds out that his gf is not actually a virgin, like first off, what does virginity have to do with love? & second, who would actually believe that she was telling the truth when she said that she was a virgin? & then Owen Wilson's character fall in love with Rachel's McAdams character and well, that's the usual predictable romance plot. the problem with this film is it's not that funny. it seems to think it's better then it is. I don't think I hardly laughed during this film. the part about the \"supposive\" gay guy like people think he is gay so therefore of course, because it's this kind of film, he ends up being gay and of course, he tries to hit on Vince Vaughn's character in a scene that is beyond creepy. lets just say that \"gay\" guy is prob one of the worst actors I've seen. & then we get a cameo from Will Ferrell, alot of people I know find this guy \"so\" funny. but I don't get it. it just wasn't funny to me. u know, I loved the classic, \"American Pie\" that was just stupid for its own good but it delivered the goods to make it a great comedy! this film wasn't so much funny as stupid. & for the most part, I'm not going to remember this film in 5 years from now because it's just an average film\n",
      "\n",
      "Review:\n",
      "Wedding Crashers is the kinda film alot of people will love because it is stupid but alot of others like myself, won't enjoy. two womanizers fall in love, one because he finds out that his gf is not actually a virgin, like first off, what does virginity have to do with love? & second, who would actually believe that she was telling the truth when she said that she was a virgin? & then Owen Wilson's character fall in love with Rachel's McAdams character and well, that's the usual predictable romance plot. the problem with this film is it's not that funny. it seems to think it's better then it is. I don't think I hardly laughed during this film. the part about the \"supposive\" gay guy like people think he is gay so therefore of course, because it's this kind of film, he ends up being gay and of course, he tries to hit on Vince Vaughn's character in a scene that is beyond creepy. lets just say that \"gay\" guy is prob one of the worst actors I've seen. & then we get a cameo from Will Ferrell, alot of people I know find this guy \"so\" funny. but I don't get it. it just wasn't funny to me. u know, I loved the classic, \"American Pie\" that was just stupid for its own good but it delivered the goods to make it a great comedy! this film wasn't so much funny as stupid. & for the most part, I'm not going to remember this film in 5 years from now because it's just an average film\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>believe</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>telling</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>laughed</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'ve</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>does</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>think</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>was</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>say</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>know</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>going</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>get</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fall</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tries</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ends</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>would</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>love</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>think</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>loved</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>know</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>will</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>have</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wo</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>'m</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>seems</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>lets</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>get</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>finds</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>think</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>remember</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>delivered</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>seen</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>hit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>said</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>make</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>being</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb has nsubj?\n",
       "0     believe        yes\n",
       "1          's        yes\n",
       "2          is        yes\n",
       "3        find           \n",
       "4     telling        yes\n",
       "5          's        yes\n",
       "6     laughed        yes\n",
       "7         've           \n",
       "8         was        yes\n",
       "9        does           \n",
       "10        was        yes\n",
       "11         do           \n",
       "12         is        yes\n",
       "13        was        yes\n",
       "14      enjoy        yes\n",
       "15         's        yes\n",
       "16         do           \n",
       "17      think           \n",
       "18        was           \n",
       "19        say           \n",
       "20       know        yes\n",
       "21      going        yes\n",
       "22        get        yes\n",
       "23       fall        yes\n",
       "24      tries        yes\n",
       "25       ends        yes\n",
       "26      would           \n",
       "27       love        yes\n",
       "28      think        yes\n",
       "29         is        yes\n",
       "30         is        yes\n",
       "31      loved        yes\n",
       "32         's        yes\n",
       "33       know        yes\n",
       "34         is        yes\n",
       "35         is        yes\n",
       "36       will           \n",
       "37       have        yes\n",
       "38         wo           \n",
       "39         'm           \n",
       "40      seems        yes\n",
       "41       lets           \n",
       "42         is        yes\n",
       "43        get        yes\n",
       "44      finds        yes\n",
       "45         do           \n",
       "46      think        yes\n",
       "47   remember           \n",
       "48         's        yes\n",
       "49  delivered        yes\n",
       "50        was        yes\n",
       "51       seen        yes\n",
       "52        hit           \n",
       "53         is        yes\n",
       "54       said        yes\n",
       "55       make           \n",
       "56      being           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "It's amazing how Hollywood and the publishing industry have bent their knees to Secession mythology, from Birth of a Nation to the present example of melodramatic falsification. This is a very dull, shapeless, stilted movie. I wouldn't bother to denounce it on artistic grounds, but since it is above all a piece of propaganda, I'm compelled to condemn it as history. What it presents is the \"War between the States\" version of the Civil War, in which the gallant Southerners defend their homes,their beloved hills and dales, their cultured lives from the inexplicable invasion of the rude hordes of the North. There are only two Black characters, both sentimentally loyal to their Southernness and their masters; otherwise, slavery is beside the point. The generalship of Lee and Jackson, of course, is idolized, while the Northern officers above the rank of colonel are portrayed as fools. The battle scenes are perfectly predictable; guys charge on foot, other guys shoot, the fields are littered with bodies. Wouldn't a little exposition of the logistics of those battle been more interesting? How real is it to show only one train, and that Southern, in a war won more by transportation than by musketry? If you are a believer in the myth of the Lost Cause and the justice of Secession, if you have ever cottoned to the notion that the War wasn't really about slavery, then I challenge you honor! I defy you to read just one heavy, scholarly book, Arguing About Slavery by William Lee Miller, a professor at the University of Virginia. It retells the debates that occurred in the House of Representatives, over slavery, in the 1830s, twenty-five years before the election of Lincoln. The uncompromising sectional hatred expressed in those debates will surely convince you that the Civil War had deeper roots than you thought, and that slavery Was indeed the central issue for both sides, Blue and Grey\n",
      "\n",
      "Review:\n",
      "It's amazing how Hollywood and the publishing industry have bent their knees to Secession mythology, from Birth of a Nation to the present example of melodramatic falsification. This is a very dull, shapeless, stilted movie. I wouldn't bother to denounce it on artistic grounds, but since it is above all a piece of propaganda, I'm compelled to condemn it as history. What it presents is the \"War between the States\" version of the Civil War, in which the gallant Southerners defend their homes,their beloved hills and dales, their cultured lives from the inexplicable invasion of the rude hordes of the North. There are only two Black characters, both sentimentally loyal to their Southernness and their masters; otherwise, slavery is beside the point. The generalship of Lee and Jackson, of course, is idolized, while the Northern officers above the rank of colonel are portrayed as fools. The battle scenes are perfectly predictable; guys charge on foot, other guys shoot, the fields are littered with bodies. Wouldn't a little exposition of the logistics of those battle been more interesting? How real is it to show only one train, and that Southern, in a war won more by transportation than by musketry? If you are a believer in the myth of the Lost Cause and the justice of Secession, if you have ever cottoned to the notion that the War wasn't really about slavery, then I challenge you honor! I defy you to read just one heavy, scholarly book, Arguing About Slavery by William Lee Miller, a professor at the University of Virginia. It retells the debates that occurred in the House of Representatives, over slavery, in the 1830s, twenty-five years before the election of Lincoln. The uncompromising sectional hatred expressed in those debates will surely convince you that the Civil War had deeper roots than you thought, and that slavery Was indeed the central issue for both sides, Blue and Grey\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>challenge</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cottoned</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>been</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bother</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>retells</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>presents</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>read</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>had</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>condemn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>occurred</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'s</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>idolized</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>are</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Arguing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>would</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>show</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>convince</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>defy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>thought</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>denounce</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>are</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'m</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>portrayed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>are</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>shoot</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>defend</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>are</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>won</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>compelled</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>charge</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>are</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>littered</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>expressed</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb has nsubj?\n",
       "0       Would           \n",
       "1   challenge        yes\n",
       "2        will           \n",
       "3    cottoned        yes\n",
       "4        been           \n",
       "5          is           \n",
       "6      bother        yes\n",
       "7     retells        yes\n",
       "8    presents        yes\n",
       "9        read           \n",
       "10        had        yes\n",
       "11    condemn           \n",
       "12   occurred        yes\n",
       "13         's        yes\n",
       "14   idolized           \n",
       "15        are           \n",
       "16         is        yes\n",
       "17    Arguing           \n",
       "18       have           \n",
       "19         is           \n",
       "20      would           \n",
       "21       have           \n",
       "22       show           \n",
       "23   convince           \n",
       "24       defy        yes\n",
       "25    thought        yes\n",
       "26   denounce           \n",
       "27        are        yes\n",
       "28         'm           \n",
       "29  portrayed           \n",
       "30        are        yes\n",
       "31      shoot        yes\n",
       "32         is        yes\n",
       "33     defend        yes\n",
       "34        are           \n",
       "35       bent        yes\n",
       "36        won        yes\n",
       "37  compelled           \n",
       "38        was        yes\n",
       "39        Was        yes\n",
       "40     charge        yes\n",
       "41        are           \n",
       "42   littered           \n",
       "43         is        yes\n",
       "44  expressed        yes\n",
       "45         is        yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Maybe for some people, to spend 40 days without sex is not big deal, but in Matt Sullivan's case, it could be a total nightmare.\n",
      "After his girlfriend Nicole leaves him, Matt spends about six months devouring girls, until he starts to hallucinate. Advised by his brother, Matt decides that celibacy is the answer to his problems, and proposes to go through lent without sex.\n",
      "For Matt's friends, this odyssey is as absurd as impossible, and immediately they take advantage of the situation to make bets about how long will last Matt's abstinence. He doesn't have it easy, as many temptations will make him suffer, and even smell the possibility of a new love.\n",
      "40 days and 40 nights is a movie that tries to get the most comedy possible out of the sexual frustration of his leading character. In a similar way that other grotesque comedies have try to explode in the past years, this film tries to sell us the idea that relationships based only in sex are less satisfactory than those based on love. OH. WHAT A SHOCKING DISCOVERY!\n",
      "\n",
      "Review:\n",
      "Maybe for some people, to spend 40 days without sex is not big deal, but in Matt Sullivan's case, it could be a total nightmare.\n",
      "After his girlfriend Nicole leaves him, Matt spends about six months devouring girls, until he starts to hallucinate. Advised by his brother, Matt decides that celibacy is the answer to his problems, and proposes to go through lent without sex.\n",
      "For Matt's friends, this odyssey is as absurd as impossible, and immediately they take advantage of the situation to make bets about how long will last Matt's abstinence. He doesn't have it easy, as many temptations will make him suffer, and even smell the possibility of a new love.\n",
      "40 days and 40 nights is a movie that tries to get the most comedy possible out of the sexual frustration of his leading character. In a similar way that other grotesque comedies have try to explode in the past years, this film tries to sell us the idea that relationships based only in sex are less satisfactory than those based on love. OH. WHAT A SHOCKING DISCOVERY!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>based</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tries</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suffer</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>based</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decides</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tries</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>take</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hallucinate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spend</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>does</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>will</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>explode</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>could</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>get</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>proposes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>make</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>make</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>be</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sell</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>devouring</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Advised</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>will</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>is</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>have</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>spends</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>starts</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>leaves</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>are</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>smell</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>last</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           verb has nsubj?\n",
       "0         based           \n",
       "1         tries        yes\n",
       "2            go           \n",
       "3        suffer        yes\n",
       "4         based           \n",
       "5       decides        yes\n",
       "6            is        yes\n",
       "7         tries        yes\n",
       "8            is        yes\n",
       "9          take        yes\n",
       "10  hallucinate           \n",
       "11        spend        yes\n",
       "12         does           \n",
       "13         will           \n",
       "14      explode           \n",
       "15        could           \n",
       "16           is           \n",
       "17          get           \n",
       "18     proposes           \n",
       "19         make        yes\n",
       "20         make           \n",
       "21           be        yes\n",
       "22         sell           \n",
       "23    devouring           \n",
       "24         have           \n",
       "25      Advised           \n",
       "26         will           \n",
       "27           is        yes\n",
       "28         have        yes\n",
       "29       spends        yes\n",
       "30       starts        yes\n",
       "31       leaves        yes\n",
       "32          are        yes\n",
       "33        smell           \n",
       "34         last           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Great movie but CD not perfoming in the last few scenes.  It gets stuck or restarts itself.  Very frustrating and more frustrating to have to return new CD\n",
      "\n",
      "Review:\n",
      "Great movie but CD not perfoming in the last few scenes.  It gets stuck or restarts itself.  Very frustrating and more frustrating to have to return new CD\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>restarts</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perfoming</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gets</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>return</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        verb has nsubj?\n",
       "0       have           \n",
       "1   restarts           \n",
       "2  perfoming           \n",
       "3       gets           \n",
       "4     return           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Editorial Reviews\n",
      "\n",
      "Amazon.com essential video\n",
      "After initially rejecting the role as too sentimental, Ginger Rogers found the title character of Kitty Foyle to be an Oscar winner and a career breakthrough. Released in 1940, only a year after her nine-picture partnership with Fred Astaire ended, Kitty Foyle helped establish Rogers as a nonmusical box-office star. The film portrays a white-collar working girl who receives a warm and welcome marriage proposal from Mark (James Craig), a kindly but humble doctor. As soon as she accepts, however, she receives a different proposition, this one from her former love, wealthy socialite Wyn (Dennis Morgan), who plans to flee his life and his wife and asks Kitty to join him and live in unwedded bliss in South America. Kitty then recounts her life in flashback to help her choose which man to love. Rogers gives an appealing performance as the feisty yet vulnerable Kitty, who makes up in moxie what she lacks in social status. Did she really deserve the Best Actress Oscar over Bette Davis in The Letter, Joan Fontaine in Rebecca, Katharine Hepburn in The Philadelphia Story, and Martha Scott in Our Town? Well, evidently Rogers had real-life moxie too. --David Horiuchi \n",
      "\n",
      "Product Description\n",
      "Known for light comedies and her partnership with Fred Astaire, Ginger Rogers stepped off the dance floor and into 1940's Oscar spotlight with her Best Actress turn as Kitty, an indomitable working-class girl who endures the rejection of Philadelphia society, makes her own way as a single woman and ultimately chooses between an unmarried arrangement with Main Line scion Wynnewood Strafford VI (Dennis Morgan) or marriage to a struggling physician (James Craig). Rogers' deserved Academy Award confirmed she was more than a dance star - a fact humorously underscored when she returned to the studio and was greeted by staffers and actors in top hats and tails. Jane Wyman won the Best Actress Academy Award for her sensitive portrayal of Belinda, capturing the girl's affecting isolation, awakening desire to learn and ultimate triumph. Directed by Jean Negulesco and co-starring Lew Ayres, Charles Bickford and Agnes Moorehead (all four Oscar nominees* for their fine work), Johnny Belinda (nominated for a total 11 Oscars including Best Picture) blends atmosphere, nuance and high drama into a heartbreaking classi\n",
      "\n",
      "Review:\n",
      "Editorial Reviews\n",
      "\n",
      "Amazon.com essential video\n",
      "After initially rejecting the role as too sentimental, Ginger Rogers found the title character of Kitty Foyle to be an Oscar winner and a career breakthrough. Released in 1940, only a year after her nine-picture partnership with Fred Astaire ended, Kitty Foyle helped establish Rogers as a nonmusical box-office star. The film portrays a white-collar working girl who receives a warm and welcome marriage proposal from Mark (James Craig), a kindly but humble doctor. As soon as she accepts, however, she receives a different proposition, this one from her former love, wealthy socialite Wyn (Dennis Morgan), who plans to flee his life and his wife and asks Kitty to join him and live in unwedded bliss in South America. Kitty then recounts her life in flashback to help her choose which man to love. Rogers gives an appealing performance as the feisty yet vulnerable Kitty, who makes up in moxie what she lacks in social status. Did she really deserve the Best Actress Oscar over Bette Davis in The Letter, Joan Fontaine in Rebecca, Katharine Hepburn in The Philadelphia Story, and Martha Scott in Our Town? Well, evidently Rogers had real-life moxie too. --David Horiuchi \n",
      "\n",
      "Product Description\n",
      "Known for light comedies and her partnership with Fred Astaire, Ginger Rogers stepped off the dance floor and into 1940's Oscar spotlight with her Best Actress turn as Kitty, an indomitable working-class girl who endures the rejection of Philadelphia society, makes her own way as a single woman and ultimately chooses between an unmarried arrangement with Main Line scion Wynnewood Strafford VI (Dennis Morgan) or marriage to a struggling physician (James Craig). Rogers' deserved Academy Award confirmed she was more than a dance star - a fact humorously underscored when she returned to the studio and was greeted by staffers and actors in top hats and tails. Jane Wyman won the Best Actress Academy Award for her sensitive portrayal of Belinda, capturing the girl's affecting isolation, awakening desire to learn and ultimate triumph. Directed by Jean Negulesco and co-starring Lew Ayres, Charles Bickford and Agnes Moorehead (all four Oscar nominees* for their fine work), Johnny Belinda (nominated for a total 11 Oscars including Best Picture) blends atmosphere, nuance and high drama into a heartbreaking classi\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>has nsubj?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>receives</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capturing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accepts</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blends</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>confirmed</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gives</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>receives</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>join</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Did</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>including</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>learn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recounts</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>endures</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>live</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>starring</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>affecting</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nominated</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rejecting</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>struggling</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>greeted</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>flee</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>plans</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>awakening</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>underscored</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>choose</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>establish</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lacks</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>had</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>turn</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>helped</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>found</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>deserved</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ended</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>was</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>asks</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>was</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>stepped</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>makes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>returned</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>be</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Known</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>portrays</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>makes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>chooses</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Directed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>working</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>won</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>help</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>deserve</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           verb has nsubj?\n",
       "0      Released           \n",
       "1          love           \n",
       "2      receives        yes\n",
       "3     capturing           \n",
       "4       accepts        yes\n",
       "5        blends        yes\n",
       "6     confirmed        yes\n",
       "7         gives        yes\n",
       "8      receives        yes\n",
       "9          join           \n",
       "10          Did           \n",
       "11    including           \n",
       "12        learn           \n",
       "13     recounts        yes\n",
       "14      endures        yes\n",
       "15         live           \n",
       "16     starring           \n",
       "17    affecting           \n",
       "18    nominated           \n",
       "19    rejecting           \n",
       "20   struggling           \n",
       "21      greeted           \n",
       "22         flee           \n",
       "23        plans        yes\n",
       "24    awakening           \n",
       "25  underscored           \n",
       "26       choose           \n",
       "27    establish           \n",
       "28        lacks        yes\n",
       "29          had        yes\n",
       "30         turn        yes\n",
       "31       helped        yes\n",
       "32        found        yes\n",
       "33     deserved           \n",
       "34        ended        yes\n",
       "35          was           \n",
       "36         asks        yes\n",
       "37          was        yes\n",
       "38      stepped        yes\n",
       "39        makes        yes\n",
       "40     returned        yes\n",
       "41           be        yes\n",
       "42        Known        yes\n",
       "43     portrays        yes\n",
       "44        makes        yes\n",
       "45      chooses        yes\n",
       "46     Directed           \n",
       "47      working           \n",
       "48          won        yes\n",
       "49         help           \n",
       "50      deserve        yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews = dvd_reviews[:10]\n",
    "for review in reviews:\n",
    "    parsed_review = nlp(review)\n",
    "    print(\"Review:\\n\\n{}\".format(review))\n",
    "    all_verbs = set()\n",
    "    verbs_with_nsubj = set()\n",
    "    for token in parsed_review:\n",
    "        if token.pos_ == 'VERB':\n",
    "            all_verbs.add(token)\n",
    "            for child in token.children:\n",
    "                if child.dep_ == 'nsubj':\n",
    "                    verbs_with_nsubj.add(token)\n",
    "                    break\n",
    "    print(\"Review:\\n{}\".format(review))\n",
    "    df = pd.DataFrame([(verb,verb in verbs_with_nsubj) for verb in all_verbs],\n",
    "                      columns=[\"verb\",'has nsubj?'])\n",
    "    df.loc[:, 'has nsubj?':'has nsubj?'] = (df.loc[:, 'has nsubj?':'has nsubj?']\n",
    "                                       .applymap(lambda x: 'yes' if x else ''))\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the next line and then run the cell to load a solution\n",
    "#%load solutions/verbs_with_subj_and_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Now adapt the code you wrote for the last exercise so that it displays a table with one column for each verb that appeared with at least one (`nsubj`,`dobj`) pair. The column for a verb should contains all the (`nsubj`,`dobj`) pairs that occurred with that verb.\n",
    "\n",
    "So a verb that occurred three times in the review in a situation where it had both an `nsubj` and a `dobj` would have entries in rows 0, 1 and 2, with each entry being the pair of tokens, i.e. the verbs `nsubj` and `dobj`. \n",
    "\n",
    "- Use a dictionary to store the (`nsubj`,`dobj`) pair details of each verb. \n",
    "- Store each verb's (`nsubj`,`dobj`) pairs in a list.\n",
    "- Put all of the lists of (`nsubj`,`dobj`) pairs into a list of lists of pairs, called `all_pairs`\n",
    "- Put the verbs in a list called `verbs` that is ordered in a way that aligns with the ordering in `all_pairs`.\n",
    "- Put this into a Pandas dataframe\n",
    " - use `pd.DataFrame(list(zip_longest(*all_pairs)),columns = verbs).applymap(lambda x: '' if x == None else x)` \n",
    " - see [unpack argument lists](https://docs.python.org/3/tutorial/controlflow.html#tut-unpacking-arguments) for an explanation of the `*`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the next line and then run the cell to load a solution\n",
    "#%load solutions/verbs_with_subj_obj_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct object relation\n",
    "The direct object of a verb, is the recipient of the action. So in \"I bought Shrek\", \"Shrek\" is the direct object of a buying action. So, for example, if we were to look for the direct objects of the verbs \"want\", \"buy\" and \"love\" we would find the words which are wanted, bought and loved. This relation is called `dobj`.\n",
    "\n",
    "### Exercise\n",
    "In the blank cell below, write code that finds all of the reviews in the DVD review set that contain the verbs \"love\", \"buy\" or \"want\". For each of these verbs, collect all the words that lie in the `dobj` relation with them, and show the results in a table. There should be one column for each of the three verbs.\n",
    "- To make the code general, do this: `target_verbs = [\"love\",\"buy\",\"want\"]`.\n",
    "- Our three target words are verb lemmas, so check their equality using `.lemma_`.\n",
    "- When you are debugging your code, don't run it on the whole dataset.\n",
    "- You can store the direct objects using a dictionary of lists and convert to a dataframe in the same way that was recommended for the previous exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the next line and then run the cell to load a solution\n",
    "#%load solutions/love_buy_want_objs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
